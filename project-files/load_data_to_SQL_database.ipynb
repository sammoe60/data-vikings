{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populating our SQL Database\n",
    "\n",
    "**Abstract**\n",
    "\n",
    "This notebook contains the code that we used to load our data (uploaded to a blob container on Azure upon transformation) to our SQL database. Any sensitive information has been removed from this notebook and replace with ''. This notebook was first generated in Azure Databricks and then exported to this Jupyter notebook. To be executed, this notebook must be exported back to Databricks. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection Strings to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = ''\n",
    "user = ''\n",
    "password = ''\n",
    "server = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84db1351-3648-4745-9edd-69ee73a518a8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Creating a Mount Point to a Blob Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aafaf64a-6998-41d0-b604-915ddc1f4f69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Mount Point through Oauth security.\n",
    "client_id = ''\n",
    "client_secret = ''\n",
    "tenant_id = ''\n",
    "\n",
    "storage_account = ''\n",
    "storage_container = ''\n",
    "\n",
    "### Name of the mount point\n",
    "mount_point = \"/mnt/data_vikings\"\n",
    "\n",
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "       \"fs.azure.account.oauth2.client.id\": client_id,\n",
    "       \"fs.azure.account.oauth2.client.secret\": client_secret,\n",
    "       \"fs.azure.account.oauth2.client.endpoint\": f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\",\n",
    "       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n",
    "\n",
    "try: \n",
    "    dbutils.fs.unmount(mount_point)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "dbutils.fs.mount(\n",
    "source = f\"abfss://{storage_container}@{storage_account}.dfs.core.windows.net/\",\n",
    "mount_point = mount_point,\n",
    "extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7fb9240-17a9-4330-98ef-6d4db043661d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Checking to see what files are in the blob container\n",
    "\n",
    "display(dbutils.fs.ls(\"/mnt/data-vikings\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**State Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74f64931-9f2d-4f81-8a8d-f0e4d709df85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Reading in the file and storing the data in a dataframe\n",
    "\n",
    "state_poverty_df = spark.read.csv('/mnt/data-vikings/state_poverty.csv', header = True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ade0cc1b-a6f1-4e13-b75f-a829c2056dda",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 1. Selecting the 'State' column\n",
    "### 2. Dropping duplicates\n",
    "### 3. Sorting the states in alphabetical order\n",
    "### 4. Renaming the column\n",
    "\n",
    "state_df = state_poverty_df.select('STATE').dropDuplicates().sort('STATE').withColumnRenamed('STATE', 'state_name')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Occupation Group Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28f85064-df87-4355-8caf-9050d0bf63dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Reading in the file and storing the data in a dataframe\n",
    "\n",
    "national_employment_df = spark.read.csv('/mnt/data-vikings/national_salary.csv', header = True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62281958-5d4e-4853-9ced-c52401b908ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 1. Selecting 'occupation group' column\n",
    "### 2. Pulling out the unique values\n",
    "### 3. Dropping the null value\n",
    "### 4. Renaming the column\n",
    "\n",
    "occ_group_df = national_employment_df.select('OCC_GROUP').distinct().dropna().withColumnRenamed('OCC_GROUP', 'occupation_group')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b454b757-8cfa-422b-8dd9-7d5b0e058959",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**National Poverty Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd9fd118-8ffa-47d0-9273-734448e3f4d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 1. Reading in the file and storing data in a dataframe\n",
    "### 2. Renaming columns\n",
    "\n",
    "national_poverty_df = spark.read.csv('/mnt/data-vikings/national_poverty.csv', header = True, inferSchema= True)\n",
    "national_poverty_df = national_poverty_df.withColumnRenamed('PR_ALL', 'pr_all').withColumnRenamed('PR_YOUTH', 'pr_youth').withColumnRenamed('MED_HH_INCOME', 'med_hh_income').withColumnRenamed('YEAR', 'year')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**State Poverty Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953bb939-2c0d-4abd-bd63-f498ff78f7fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Reading in the file and storing the data in a dataframe\n",
    "\n",
    "state_poverty_df = spark.read.csv('/mnt/data-vikings/state_poverty.csv', header = True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c721a8d-bdae-43fc-880b-49ecbdc880d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Joining the state poverty data frame with the state dataframe\n",
    "\n",
    "state_poverty_df = state_poverty_df.join(state_df, [state_poverty_df.STATE == state_df.state_name], 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56db3316-8104-44e5-872c-780ea08d08af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 1. Dropping columns\n",
    "### 2. Renaming columns\n",
    "\n",
    "state_poverty_df = state_poverty_df.drop('STATE', 'state_name').withColumnRenamed('PR_ALL', 'pr_all').withColumnRenamed('PR_YOUTH', 'pr_youth').withColumnRenamed('MED_HH_INCOME', 'med_hh_income').withColumnRenamed('YEAR', 'year')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**County Poverty Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f25e2c08-c688-4aa2-aee2-2f3866c47a68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Reading in file and storing the data in a dataframe\n",
    "\n",
    "county_poverty_df = spark.read.csv('/mnt/data-vikings/county_poverty.csv', header = True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7234d382-ab67-49cb-929e-2be7c775635a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Joining the county poverty dataframe with the state dataframe\n",
    "\n",
    "county_poverty_df = county_poverty_df.join(state_df, [county_poverty_df.STATE_NAME == state_df.state_name], 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6bc6bb3-eb4b-41b8-a75a-b310715605a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 1. Dropping columns\n",
    "### 2. Renaming columns\n",
    "\n",
    "county_poverty_df = county_poverty_df.drop('state_name').withColumnRenamed('YEAR', 'year').withColumnRenamed('PR_ALL', 'pr_all').withColumnRenamed('PR_YOUTH', 'pr_youth').withColumnRenamed('MED_HH_INCOME', 'med_hh_income').withColumnRenamed('COUNTY_FULL', 'county').withColumnRenamed('LAT', 'latitude').withColumnRenamed('LNG', 'longitude').withColumnRenamed('POPULATION', 'population')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**National Employment Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92b892c6-a63f-4f5b-804b-83310ed2fd1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Reading in file and storing the data in a dataframe\n",
    "\n",
    "national_employment_df = spark.read.csv('/mnt/data-vikings/national_salary.csv', header = True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6cabf08-a4a0-4cb6-bb7c-ead638807c83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Joining the national employment dataframe with occupation group dataframe\n",
    "\n",
    "national_employment_df = national_employment_df.join(occupation_group_df, [national_employment_df.OCC_GROUP == occupation_group_df.occupation_group], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c715d44-b124-4eeb-a580-44541dbfa820",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 1. Dropping columns\n",
    "### 2. Renaming columns\n",
    "\n",
    "national_employment_df = national_employment_df.drop('OCC_GROUP', 'occupation_group').withColumnRenamed('OCC_TITLE', 'occ_title').withColumnRenamed('TOT_EMP', 'tot_emp').withColumnRenamed('H_MEAN', 'h_mean').withColumnRenamed('A_MEAN', 'a_mean').withColumnRenamed('H_MEDIAN', 'h_median').withColumnRenamed('A_MEDIAN', 'a_median').withColumnRenamed('YEAR', 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c0680de-201a-40ab-9eb0-28617195f21a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### 1. Reading in file and storing data in a dataframe\n",
    "### 2. Renaming columns\n",
    "\n",
    "state_employment_df = spark.read.csv('/mnt/data-vikings/state_salary.csv', header = True, inferSchema= True)\n",
    "state_employment_df = state_employment_df.withColumnRenamed('AREA', 'area').withColumnRenamed('OCC_TITLE', 'occ_title').withColumnRenamed('TOT_EMP', 'tot_emp').withColumnRenamed('JOBS_1000', 'jobs_1000').withColumnRenamed('LOC_QUOTIENT', 'loc_quotient').withColumnRenamed('H_MEAN', 'h_mean').withColumnRenamed('A_MEAN', 'a_mean').withColumnRenamed('H_MEDIAN', 'h_median').withColumnRenamed('A_MEDIAN', 'a_median').withColumnRenamed('YEAR', 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca3fcc62-a9a1-4991-95ea-c2d7b393b35f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Joining state employment dataframe with state dataframe\n",
    "\n",
    "state_employment_df = state_employment_df.join(state_df, [state_employment_df.STATE == state_df.state_name], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f02fd191-676f-4721-b7c6-56337220f8d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Joining state employment dataframe with occupation group dataframe\n",
    "\n",
    "state_employment_df = state_employment_df.join(occupation_group_df, [state_employment_df.OCC_GROUP == occupation_group_df.occupation_group], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec604937-cad7-42ad-ba61-025cf607ec39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Dropping columns\n",
    "\n",
    "state_employment_df = state_employment_df.drop('STATE', 'OCC_GROUP', 'state_name', 'occupation_group')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Poverty Threshold Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in file and storing data in a dataframe\n",
    "\n",
    "poverty_threshold_df = spark.read.csv('/mnt/data-vikings/poverty_threshold.csv', header = True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Renaming columns\n",
    "\n",
    "poverty_threshold_df = poverty_threshold_df.withColumnRenamed('1 Person' , 'amount_for_one_person')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Data to SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = 'dbo.state'\n",
    "table2 = 'dbo.occupation_group'\n",
    "table3 = 'dbo.national_poverty'\n",
    "table4 = 'dbo.state_poverty'\n",
    "table5 = 'dbo.county_poverty'\n",
    "table6 = 'dbo.national_employment'\n",
    "table7 = 'dbo.state_employment'\n",
    "table8 = 'dbo.poverty_threshold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0f697b-2546-4d57-97b2-971b2fd3a57c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "state_df.write.format(\"jdbc\").option(\n",
    "    \"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\"\n",
    "    ) \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"dbtable\", table1) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .save()\n",
    "\n",
    "occ_group_df.write.format(\"jdbc\").option(\n",
    "    \"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\"\n",
    "    ) \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"dbtable\", table1) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .save()\n",
    "\n",
    "national_poverty_df.write.format(\"jdbc\").option(\n",
    "    \"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\"\n",
    "    ) \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"dbtable\", table3) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .save()\n",
    "\n",
    "state_poverty_df.write.format(\"jdbc\").option(\n",
    "    \"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\"\n",
    "    ) \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"dbtable\", table4) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .save()\n",
    "\n",
    "county_poverty_df.write.format(\"jdbc\").option(\n",
    "    \"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\"\n",
    "    ) \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"dbtable\", table5) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .save()\n",
    "\n",
    "national_employment_df.write.format(\"jdbc\").option(\n",
    "    \"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\"\n",
    "    ) \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"dbtable\", table6) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .save()\n",
    "\n",
    "state_employment_df.write.format(\"jdbc\").option(\n",
    "    \"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\"\n",
    "    ) \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"dbtable\", table5) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .save()\n",
    "\n",
    "poverty_threshold_df.write.format(\"jdbc\").option(\n",
    "    \"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\"\n",
    "    ) \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"dbtable\", table8) \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Load_Data_to_SQL",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
