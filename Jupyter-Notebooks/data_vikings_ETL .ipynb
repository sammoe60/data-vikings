{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (E)xtract (T)ransform (L)oad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract**\n",
    "\n",
    "This notebook contains the the code that we used to extract and transform our different datasets. The final step in the ETL process (Load) can be found [here](../Database/load_data_to_SQL_database.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helpful function used throughout the notebook to uppercase all column headings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_columns(data):\n",
    "    columns = data\n",
    "    myList = []\n",
    "    for name in columns:\n",
    "        myList.append(name.upper())\n",
    "    data.columns = myList"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census.gov API Call \n",
    "\n",
    "https://www.census.gov/data/developers/data-sets/Poverty-Statistics.html\n",
    "\n",
    "3 API calls to collect the poverty data on a national, state, and county level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_url ='https://api.census.gov/data/timeseries/poverty/saipe?get=SAEPOVRTALL_PT,SAEPOVRT0_17_PT,SAEMHI_PT,YEAR&for=us'\n",
    "state_url = 'https://api.census.gov/data/timeseries/poverty/saipe?get=NAME,SAEPOVRTALL_PT,SAEPOVRT0_17_PT,SAEMHI_PT,YEAR&for=state:*'\n",
    "county_url = 'https://api.census.gov/data/timeseries/poverty/saipe?get=NAME,SAEPOVRTALL_PT,SAEPOVRT0_17_PT,SAEMHI_PT,YEAR&for=county:*'\n",
    "\n",
    "national_poverty_response = requests.get(national_url)\n",
    "state_poverty_response = requests.get(state_url)\n",
    "county_poverty_response = requests.get(county_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting the responses from the API calls into JSON format\n",
    "\n",
    "national_poverty_response_json = national_poverty_response.json()\n",
    "state_poverty_response_json = state_poverty_response.json()\n",
    "county_poverty_response_json = county_poverty_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Storing the JSON into different dataframes\n",
    "\n",
    "poverty_nat = pd.DataFrame(national_poverty_response_json[1:], columns = national_poverty_response_json[0])\n",
    "poverty_state = pd.DataFrame(state_poverty_response_json[1:], columns = state_poverty_response_json[0])\n",
    "poverty_county = pd.DataFrame(county_poverty_response_json[1:], columns = county_poverty_response_json[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kendr\\AppData\\Local\\Temp\\ipykernel_16116\\3003373859.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  state_name_df.rename(columns={'NAME': \"STATE_NAME\"}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "### 1. Create dataframe for state names\n",
    "### 2. Rename columns\n",
    "### 3. Generating another dataframe by merging new dataframe with county poverty dataframe\n",
    "### 4. Dropping any duplicates\n",
    "\n",
    "state_name_df = poverty_state[['NAME','state']]\n",
    "state_name_df.rename(columns={'NAME': \"STATE_NAME\"}, inplace=True)\n",
    "poverty_county_state = state_name_df.merge(poverty_county, on='state')\n",
    "poverty_county_state = poverty_county_state.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dropping and renaming columns\n",
    "\n",
    "poverty_state = poverty_state.drop(columns='state')\n",
    "poverty_nat = poverty_nat.drop(columns='us')\n",
    "\n",
    "poverty_state = poverty_state.rename(columns={\"NAME\": \"STATE\", \"SAEPOVRTALL_PT\": \"PR_ALL\", \"SAEPOVRT0_17_PT\": \"PR_YOUTH\", 'SAEMHI_PT': 'MED_HH_INCOME' })\n",
    "poverty_nat = poverty_nat.rename(columns={\"NAME\": \"STATE\", \"SAEPOVRTALL_PT\": \"PR_ALL\", \"SAEPOVRT0_17_PT\": \"PR_YOUTH\", 'SAEMHI_PT': 'MED_HH_INCOME' })\n",
    "\n",
    "\n",
    "poverty_county_state = poverty_county_state.drop(columns='state')\n",
    "poverty_county_state = poverty_county_state.rename(columns={\"NAME\": \"COUNTY\", \"SAEPOVRTALL_PT\": \"PR_ALL\", \"SAEPOVRT0_17_PT\": \"PR_YOUTH\", 'SAEMHI_PT': 'MED_HH_INCOME' })\n",
    "poverty_county_state = poverty_county_state.drop(columns='county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Changing the datatypes \n",
    "\n",
    "poverty_state = poverty_state.astype({'PR_ALL': float, 'PR_YOUTH': float, 'MED_HH_INCOME': float, 'YEAR': int})\n",
    "poverty_nat = poverty_nat.astype({'PR_ALL': float, 'PR_YOUTH': float, 'MED_HH_INCOME': float, 'YEAR': int})\n",
    "poverty_county_state = poverty_county_state.astype({'PR_ALL': float, 'PR_YOUTH': float, 'MED_HH_INCOME': float, 'YEAR': int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filtering out certain values from the 'STATE' column\n",
    "\n",
    "poverty_state = poverty_state[poverty_state['STATE'] != 'Guam'] \n",
    "poverty_state = poverty_state[poverty_state['STATE'] != 'Puerto Rico'] \n",
    "poverty_state = poverty_state[poverty_state['STATE'] != 'Virgin Islands']\n",
    "poverty_state = poverty_state[poverty_state['STATE'] != 'District of Columbia']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## County Dataset with Latitude/Longitude/Population"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset obtained from: https://simplemaps.com/data/us-counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in the CSV and saving the data in a dataframe\n",
    "\n",
    "uscounties_df = pd.read_csv(\"../data/uscounties.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uppercasing column headings\n",
    "\n",
    "upper_columns(uscounties_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a new dataframe by merging LAT/LONG/POP with county poverty dataset\n",
    "\n",
    "county_locs_df = poverty_county_state.merge(uscounties_df, how='left', left_on=['STATE_NAME', 'COUNTY'], right_on=['STATE_NAME', 'COUNTY_FULL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filtering out what columns to select\n",
    "\n",
    "county_final = county_locs_df[['STATE_NAME','YEAR','PR_ALL','PR_YOUTH','MED_HH_INCOME','COUNTY_FULL','LAT','LNG','POPULATION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing population data from all years except 2020\n",
    "\n",
    "for i in range(len(county_final)):\n",
    "    if county_final.loc[i, \"YEAR\"] != 2020:\n",
    "        county_final.loc[i,'POPULATION'] = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## County Unemployment Rate Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_UE_df = pd.read_csv(\"../data/A-L_unemployment.csv\")\n",
    "MZ_UE_df = pd.read_csv(\"../data/M-Z_unemployment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "al_transpose = AL_UE_df.transpose()\n",
    "mz_transpose = MZ_UE_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_df = pd.concat([al_transpose, mz_transpose], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kendr\\AppData\\Local\\Temp\\ipykernel_16116\\3964193905.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unemployment_df2['STATE_NAME'] = \"Minnesota\"\n"
     ]
    }
   ],
   "source": [
    "header = unemployment_df.iloc[0]\n",
    "unemployment_df2 = unemployment_df[1:]\n",
    "unemployment_df2.columns = header\n",
    "unemployment_df2.columns\n",
    "unemployment_df2['STATE_NAME'] = \"Minnesota\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ue_df = unemployment_df2.rename(columns={ '2022 Annual Avg.' : '2022', '2021 Annual Avg.': '2021', '2020 Annual Avg.' : '2020',\n",
    "       '2019 Annual Avg.': '2019', '2018 Annual Avg.': '2018', '2017 Annual Avg.': '2017',\n",
    "       '2016 Annual Avg.': '2016', '2015 Annual Avg.': '2015', '2014 Annual Avg.': '2014',\n",
    "       '2013 Annual Avg.': '2013', '2012 Annual Avg.': '2012', '2011 Annual Avg.': '2011',\n",
    "       '2010 Annual Avg.' : '2010', '2009 Annual Avg.': '2009', '2008 Annual Avg.': '2008',\n",
    "       '2007 Annual Avg.': '2007', '2006 Annual Avg.': '2006', '2005 Annual Avg.': '2005',\n",
    "       '2004 Annual Avg.': '2004', '2003 Annual Avg.': '2003', '2002 Annual Avg.': '2002',\n",
    "       '2001 Annual Avg.': '2001'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "num_list = []\n",
    "for i in range(88):\n",
    "    i += 1\n",
    "    num_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2022', '2021', '2020', '2019', '2018', '2017', '2016', '2015', '2014',\n",
       "       '2013', '2012', '2011', '2010', '2009', '2008', '2007', '2006', '2005',\n",
       "       '2004', '2003', '2002', '2001', 'STATE_NAME', 'COUNTY_FULL'],\n",
       "      dtype='object', name='Year/Month')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ue_df['COUNTY_FULL'] = ue_df.index\n",
    "ue_df.index = num_list\n",
    "\n",
    "ue_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_columns(ue_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ue_df_unpivot = pd.melt(ue_df, id_vars=['COUNTY_FULL', 'STATE_NAME'], value_vars = ['2022', '2021', '2020', '2019', '2018', '2017', '2016', '2015', '2014',\n",
    "       '2013', '2012', '2011', '2010', '2009', '2008', '2007', '2006', '2005',\n",
    "       '2004', '2003', '2002', '2001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ue_df_unpivot2 = ue_df_unpivot.rename(columns={ 'COUNTY': 'COUNTY_FULL', 'variable' : 'YEAR', 'value': 'UE_RATE', })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ue_df_unpivot3 = ue_df_unpivot2[ue_df_unpivot2.COUNTY_FULL != 'Year/Month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ue_final = ue_df_unpivot3.astype({'YEAR': int, 'UE_RATE': float})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## National Employment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Tables obtained from: https://www.bls.gov/oes/tables.htm\n",
    " \n",
    " *Tables Created by BLS : U.S. Bureau of Labor Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in Excel files and saving all data into dataframes\n",
    "\n",
    "national2001_df = pd.read_excel(\"../data/national_M2001_dl.xls\")\n",
    "national2002_df = pd.read_excel(\"../data/national_M2002_dl.xls\")\n",
    "national2003_df = pd.read_excel(\"../data/national_M2003_dl.xls\")\n",
    "national2004_df = pd.read_excel(\"../data/national_M2004_dl.xls\")\n",
    "national2005_df = pd.read_excel(\"../data/national_M2005_dl.xls\")\n",
    "national2006_df = pd.read_excel(\"../data/national_M2006_dl.xls\")\n",
    "national2007_df = pd.read_excel(\"../data/national_M2007_dl.xls\")\n",
    "national2008_df = pd.read_excel(\"../data/national_M2008_dl.xls\")\n",
    "national2009_df = pd.read_excel(\"../data/national_M2009_dl.xls\")\n",
    "national2010_df = pd.read_excel(\"../data/national_M2010_dl.xls\")\n",
    "national2011_df = pd.read_excel(\"../data/national_M2011_dl.xls\")\n",
    "national2012_df = pd.read_excel(\"../data/national_M2012_dl.xls\")\n",
    "national2013_df = pd.read_excel(\"../data/national_M2013_dl.xls\")\n",
    "national2014_df = pd.read_excel(\"../data/national_M2014_dl.xlsx\")\n",
    "national2015_df = pd.read_excel(\"../data/national_M2015_dl.xlsx\")\n",
    "national2016_df = pd.read_excel(\"../data/national_M2016_dl.xlsx\")\n",
    "national2017_df = pd.read_excel(\"../data/national_M2017_dl.xlsx\")\n",
    "national2018_df = pd.read_excel(\"../data/national_M2018_dl.xlsx\")\n",
    "national2019_df = pd.read_excel(\"../data/national_M2019_dl.xlsx\")\n",
    "national2020_df = pd.read_excel(\"../data/national_M2020_dl.xlsx\")\n",
    "national2021_df = pd.read_excel(\"../data/national_M2021_dl.xlsx\")\n",
    "national2022_df = pd.read_excel(\"../data/national_M2022_dl.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding a 'Year' columns to each dataframe\n",
    "\n",
    "national2002_df['Year'] = 2002\n",
    "national2003_df['Year'] = 2003\n",
    "national2004_df['Year'] = 2004\n",
    "national2005_df['Year'] = 2005\n",
    "national2006_df['Year'] = 2006\n",
    "national2007_df['Year'] = 2007\n",
    "national2008_df['Year'] = 2008\n",
    "national2009_df['Year'] = 2009\n",
    "national2010_df['Year'] = 2010\n",
    "national2011_df['Year'] = 2011\n",
    "national2012_df['Year'] = 2012\n",
    "national2013_df['Year'] = 2013\n",
    "national2014_df['Year'] = 2014\n",
    "national2015_df['Year'] = 2015\n",
    "national2016_df['Year'] = 2016\n",
    "national2017_df['Year'] = 2017\n",
    "national2018_df['Year'] = 2018\n",
    "national2019_df['Year'] = 2019\n",
    "national2020_df['Year'] = 2020\n",
    "national2021_df['Year'] = 2021\n",
    "national2022_df['Year'] = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uppercasing all column headings\n",
    "\n",
    "upper_columns(national2001_df)\n",
    "upper_columns(national2002_df)\n",
    "upper_columns(national2003_df)\n",
    "upper_columns(national2004_df)\n",
    "upper_columns(national2005_df)\n",
    "upper_columns(national2006_df)\n",
    "upper_columns(national2007_df)\n",
    "upper_columns(national2008_df)\n",
    "upper_columns(national2009_df)\n",
    "upper_columns(national2010_df)\n",
    "upper_columns(national2011_df)\n",
    "upper_columns(national2012_df)\n",
    "upper_columns(national2013_df)\n",
    "upper_columns(national2014_df)\n",
    "upper_columns(national2015_df)\n",
    "upper_columns(national2016_df)\n",
    "upper_columns(national2017_df)\n",
    "upper_columns(national2018_df)\n",
    "upper_columns(national2019_df)\n",
    "upper_columns(national2020_df)\n",
    "upper_columns(national2021_df)\n",
    "upper_columns(national2022_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Renaming columns\n",
    "\n",
    "n2001_df = national2001_df.rename(columns={ 'GROUP': 'OCC_GROUP', 'H_WPCT10' : 'H_PCT10', 'H_WPCT25' : 'H_PCT25', 'H_WPCT75' : 'H_PCT75', 'H_WPCT90' : 'H_PCT90', 'A_WPCT10' : 'A_PCT10', 'A_WPCT25' : 'A_PCT25', 'A_WPCT75' : 'A_PCT75', 'A_WPCT90' : 'A_PCT90'})\n",
    "n2002_df = national2002_df.rename(columns={ 'GROUP': 'OCC_GROUP', 'H_WPCT10' : 'H_PCT10', 'H_WPCT25' : 'H_PCT25', 'H_WPCT75' : 'H_PCT75', 'H_WPCT90' : 'H_PCT90', 'A_WPCT10' : 'A_PCT10', 'A_WPCT25' : 'A_PCT25', 'A_WPCT75' : 'A_PCT75', 'A_WPCT90' : 'A_PCT90'})\n",
    "n2003_df = national2003_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "n2004_df = national2004_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "n2005_df = national2005_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "n2006_df = national2006_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "n2007_df = national2007_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "n2008_df = national2008_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "n2009_df = national2009_df.rename(columns={'GROUP': 'OCC_GROUP'})\n",
    "n2010_df = national2010_df.rename(columns={'LOC QUOTIENT': 'LOC_QUOTIENT', 'GROUP': 'OCC_GROUP'})\n",
    "n2011_df = national2011_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT', 'GROUP': 'OCC_GROUP'})\n",
    "n2012_df = national2012_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "n2013_df = national2013_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "n2014_df = national2014_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "n2015_df = national2015_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "n2016_df = national2016_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "n2017_df = national2017_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "n2018_df = national2018_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "n2019_df = national2019_df.rename(columns={'O_GROUP': 'OCC_GROUP', 'AREA_TITLE': 'STATE'})\n",
    "n2020_df = national2020_df.rename(columns={'O_GROUP': 'OCC_GROUP', 'AREA_TITLE': 'STATE'})\n",
    "n2021_df = national2021_df.rename(columns={'O_GROUP': 'OCC_GROUP', 'AREA_TITLE': 'STATE'})\n",
    "n2022_df = national2022_df.rename(columns={'O_GROUP': 'OCC_GROUP', 'AREA_TITLE': 'STATE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filtering desired columns and assigning column order\n",
    "\n",
    "n2001_ordered = n2001_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2002_ordered = n2002_df[[\n",
    "    'OCC_CODE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2003_ordered = n2003_df[[\n",
    "  'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2004_ordered = n2004_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2005_ordered = n2005_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2006_ordered = n2006_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2007_ordered = n2007_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2008_ordered = n2008_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2009_ordered = n2009_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2010_ordered = n2010_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2011_ordered = n2011_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2012_ordered = n2012_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2013_ordered = n2013_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2014_ordered = n2014_df[[\n",
    "   'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2015_ordered = n2015_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2016_ordered = n2016_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2017_ordered = n2017_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2018_ordered = n2018_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "  'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2019_ordered = n2019_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2020_ordered = n2020_df[[\n",
    "   'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2021_ordered = n2021_df[[\n",
    "    'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "   'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "   'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "   'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "n2022_ordered = n2022_df[[\n",
    "     'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concatinating all dataframes into one dataframe\n",
    "\n",
    "national_df = pd.concat([n2001_ordered,n2002_ordered,n2003_ordered,n2004_ordered,\n",
    "                         n2005_ordered,n2006_ordered, n2007_ordered,n2008_ordered,\n",
    "                         n2009_ordered,n2010_ordered, n2011_ordered,n2012_ordered,\n",
    "                         n2013_ordered,n2014_ordered,n2015_ordered,n2016_ordered,\n",
    "                         n2017_ordered,n2018_ordered,n2019_ordered,n2020_ordered,\n",
    "                         n2021_ordered,n2022_ordered ], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filtering columns\n",
    "\n",
    "national_df = national_df[[\n",
    "    'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP', 'H_MEAN',\n",
    "    'A_MEAN', 'H_MEDIAN', 'A_MEDIAN', 'YEAR']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing certain values from the dataframe\n",
    "\n",
    "cols = list(national_df.columns)\n",
    "for col in cols: \n",
    "    national_df = national_df[national_df[col] != '#']\n",
    "    national_df = national_df[national_df[col] != '*']\n",
    "    national_df = national_df[national_df[col] != '**']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chaning datatypes\n",
    "\n",
    "nat_final_df = national_df.astype({'TOT_EMP': int, 'H_MEAN': float, 'A_MEAN': float, 'H_MEDIAN': float, 'A_MEDIAN': float, 'YEAR': int})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Employment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables obtained from: https://www.bls.gov/oes/tables.htm\n",
    "\n",
    "*Tables Created by BLS : U.S. Bureau of Labor Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in tables and storing data into different dataframes\n",
    "\n",
    "state2001_df = pd.read_excel(\"../data/state_M2001_dl.xls\")\n",
    "state2002_df = pd.read_excel(\"../data/state_M2002_dl.xls\")\n",
    "state2003_df = pd.read_excel(\"../data/state_M2003_dl.xls\")\n",
    "state2004_df = pd.read_excel(\"../data/state_M2004_dl.xls\")\n",
    "state2005_df = pd.read_excel(\"../data/state_M2005_dl.xls\")\n",
    "state2006_df = pd.read_excel(\"../data/state_M2006_dl.xls\")\n",
    "state2007_df = pd.read_excel(\"../data/state_M2007_dl.xls\")\n",
    "state2008_df = pd.read_excel(\"../data/state_M2008_dl.xls\")\n",
    "state2009_df = pd.read_excel(\"../data/state_M2009_dl.xls\")\n",
    "state2010_df = pd.read_excel(\"../data/state_M2010_dl.xls\")\n",
    "state2011_df = pd.read_excel(\"../data/state_M2011_dl.xls\")\n",
    "state2012_df = pd.read_excel(\"../data/state_M2012_dl.xls\")\n",
    "state2013_df = pd.read_excel(\"../data/state_M2013_dl.xls\")\n",
    "state2014_df = pd.read_excel(\"../data/state_M2014_dl.xlsx\")\n",
    "state2015_df = pd.read_excel(\"../data/state_M2015_dl.xlsx\")\n",
    "state2016_df = pd.read_excel(\"../data/state_M2016_dl.xlsx\")\n",
    "state2017_df = pd.read_excel(\"../data/state_M2017_dl.xlsx\")\n",
    "state2018_df = pd.read_excel(\"../data/state_M2018_dl.xlsx\")\n",
    "state2019_df = pd.read_excel(\"../data/state_M2019_dl.xlsx\")\n",
    "state2020_df = pd.read_excel(\"../data/state_M2020_dl.xlsx\")\n",
    "state2021_df = pd.read_excel(\"../data/state_M2021_dl.xlsx\")\n",
    "state2022_df = pd.read_excel(\"../data/state_M2022_dl.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a 'Year' column for each dataframe\n",
    "\n",
    "state2002_df['Year'] = 2002\n",
    "state2003_df['Year'] = 2003\n",
    "state2004_df['Year'] = 2004\n",
    "state2005_df['Year'] = 2005\n",
    "state2006_df['Year'] = 2006\n",
    "state2007_df['Year'] = 2007\n",
    "state2008_df['Year'] = 2008\n",
    "state2009_df['Year'] = 2009\n",
    "state2010_df['Year'] = 2010\n",
    "state2011_df['Year'] = 2011\n",
    "state2012_df['Year'] = 2012\n",
    "state2013_df['Year'] = 2013\n",
    "state2014_df['Year'] = 2014\n",
    "state2015_df['Year'] = 2015\n",
    "state2016_df['Year'] = 2016\n",
    "state2017_df['Year'] = 2017\n",
    "state2018_df['Year'] = 2018\n",
    "state2019_df['Year'] = 2019\n",
    "state2020_df['Year'] = 2020\n",
    "state2021_df['Year'] = 2021\n",
    "state2022_df['Year'] = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uppercasing all column headings in each dataframe\n",
    "\n",
    "upper_columns(state2001_df)\n",
    "upper_columns(state2002_df)\n",
    "upper_columns(state2003_df)\n",
    "upper_columns(state2004_df)\n",
    "upper_columns(state2005_df)\n",
    "upper_columns(state2006_df)\n",
    "upper_columns(state2007_df)\n",
    "upper_columns(state2008_df)\n",
    "upper_columns(state2009_df)\n",
    "upper_columns(state2010_df)\n",
    "upper_columns(state2011_df)\n",
    "upper_columns(state2012_df)\n",
    "upper_columns(state2013_df)\n",
    "upper_columns(state2014_df)\n",
    "upper_columns(state2015_df)\n",
    "upper_columns(state2016_df)\n",
    "upper_columns(state2017_df)\n",
    "upper_columns(state2018_df)\n",
    "upper_columns(state2019_df)\n",
    "upper_columns(state2020_df)\n",
    "upper_columns(state2021_df)\n",
    "upper_columns(state2022_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Renaming columns\n",
    "\n",
    "s2001_df = state2001_df.rename(columns={ 'GROUP': 'OCC_GROUP', 'H_WPCT10' : 'H_PCT10', 'H_WPCT25' : 'H_PCT25', 'H_WPCT75' : 'H_PCT75', 'H_WPCT90' : 'H_PCT90', 'A_WPCT10' : 'A_PCT10', 'A_WPCT25' : 'A_PCT25', 'A_WPCT75' : 'A_PCT75', 'A_WPCT90' : 'A_PCT90'})\n",
    "s2002_df = state2002_df.rename(columns={ 'GROUP': 'OCC_GROUP', 'H_WPCT10' : 'H_PCT10', 'H_WPCT25' : 'H_PCT25', 'H_WPCT75' : 'H_PCT75', 'H_WPCT90' : 'H_PCT90', 'A_WPCT10' : 'A_PCT10', 'A_WPCT25' : 'A_PCT25', 'A_WPCT75' : 'A_PCT75', 'A_WPCT90' : 'A_PCT90'})\n",
    "s2003_df = state2003_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "s2004_df = state2004_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "s2005_df = state2005_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "s2006_df = state2006_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "s2007_df = state2007_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "s2008_df = state2008_df.rename(columns={ 'GROUP': 'OCC_GROUP'})\n",
    "s2009_df = state2009_df.rename(columns={'GROUP': 'OCC_GROUP'})\n",
    "s2010_df = state2010_df.rename(columns={'LOC QUOTIENT': 'LOC_QUOTIENT', 'GROUP': 'OCC_GROUP'})\n",
    "s2011_df = state2011_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT', 'GROUP': 'OCC_GROUP'})\n",
    "s2012_df = state2012_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "s2013_df = state2013_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "s2014_df = state2014_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "s2015_df = state2015_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "s2016_df = state2016_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "s2017_df = state2017_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "s2018_df = state2018_df.rename(columns={'LOC_Q': 'LOC_QUOTIENT'})\n",
    "s2019_df = state2019_df.rename(columns={'O_GROUP': 'OCC_GROUP', 'AREA_TITLE': 'STATE'})\n",
    "s2020_df = state2020_df.rename(columns={'O_GROUP': 'OCC_GROUP', 'AREA_TITLE': 'STATE'})\n",
    "s2021_df = state2021_df.rename(columns={'O_GROUP': 'OCC_GROUP', 'AREA_TITLE': 'STATE'})\n",
    "s2022_df = state2022_df.rename(columns={'O_GROUP': 'OCC_GROUP', 'AREA_TITLE': 'STATE'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filtering columns and assigning column order\n",
    "\n",
    "s2001_ordered = s2001_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2002_ordered = s2002_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2003_ordered = s2003_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2004_ordered = s2004_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2005_ordered = s2005_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2006_ordered = s2006_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2007_ordered = s2007_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE',  'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2008_ordered = s2008_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2009_ordered = s2009_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2010_ordered = s2010_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2011_ordered = s2011_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2012_ordered = s2012_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2013_ordered = s2013_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2014_ordered = s2014_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2015_ordered = s2015_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2016_ordered = s2016_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2017_ordered = s2017_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2018_ordered = s2018_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2019_ordered = s2019_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2020_ordered = s2020_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2021_ordered = s2021_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]\n",
    "s2022_ordered = s2022_df[[\n",
    "    'AREA', 'STATE', 'OCC_CODE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'EMP_PRSE', 'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN', 'MEAN_PRSE',\n",
    "    'H_PCT10', 'H_PCT25', 'H_MEDIAN', 'H_PCT75', 'H_PCT90', 'A_PCT10',\n",
    "    'A_PCT25', 'A_MEDIAN', 'A_PCT75', 'A_PCT90', 'YEAR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concatinating all dataframes into one\n",
    "\n",
    "state_df = pd.concat([s2001_ordered, s2002_ordered, s2003_ordered,s2004_ordered,s2005_ordered,s2006_ordered\n",
    "                      ,s2007_ordered,s2008_ordered,s2009_ordered,s2010_ordered,s2011_ordered,s2012_ordered,\n",
    "                      s2013_ordered,s2014_ordered,s2015_ordered,s2016_ordered,s2017_ordered,s2018_ordered,\n",
    "                      s2019_ordered,s2020_ordered,s2021_ordered,s2022_ordered], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filtering out certain values in the 'STATE' column\n",
    "\n",
    "state_df = state_df[state_df['STATE'] != 'Guam'] \n",
    "state_df = state_df[state_df['STATE'] != 'Puerto Rico'] \n",
    "state_df = state_df[state_df['STATE'] != 'Virgin Islands']\n",
    "state_df = state_df[state_df['STATE'] != 'District of Columbia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filtering columns\n",
    "\n",
    "state_df = state_df[[\n",
    "    'AREA', 'STATE', 'OCC_TITLE', 'OCC_GROUP', 'TOT_EMP',\n",
    "    'JOBS_1000', 'LOC_QUOTIENT', 'H_MEAN', 'A_MEAN',\n",
    "    'H_MEDIAN', 'A_MEDIAN', 'YEAR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing certain values\n",
    "\n",
    "cols = list(state_df.columns)\n",
    "for col in cols:\n",
    "    state_df = state_df[state_df[col] != '#']\n",
    "    state_df = state_df[state_df[col] != '*']\n",
    "    state_df = state_df[state_df[col] != '**']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Changing datatypes\n",
    "\n",
    "state_final_df = state_df.astype({\n",
    "    'TOT_EMP': int, 'JOBS_1000': float, 'LOC_QUOTIENT': float, \n",
    "    'H_MEAN': float, 'A_MEAN': float, 'H_MEDIAN': float, \n",
    "    'A_MEDIAN': float, 'YEAR': int})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poverty Threshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel file obtained from: https://aspe.hhs.gov/topics/poverty-economic-mobility/poverty-guidelines\n",
    "\n",
    "A portion of the excel file was then saved as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in the CSV file and storing the data into a dataframe\n",
    "\n",
    "poverty_threshold_df = pd.read_csv('../data/guidelines-1983-2023.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reassigning the column headers\n",
    "\n",
    "poverty_threshold_df.columns = poverty_threshold_df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dropping certain rows and columns\n",
    "\n",
    "poverty_threshold_df = poverty_threshold_df.drop([0,1,2,44,45,46,47,48]).dropna(axis = 1).drop(columns = ['2 Persons', '3 Persons', '4 Persons', '5 Persons', '6 Persons', '7 Persons', '8 Persons', '$ For Each Additional Person (9+)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JakeUhl\\AppData\\Local\\Temp\\ipykernel_12668\\146775.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  poverty_threshold_df['1 Person'] = poverty_threshold_df['1 Person'].str.replace('$', '').str.replace(',', '')\n"
     ]
    }
   ],
   "source": [
    "### Replacing certain strings within the values\n",
    "\n",
    "poverty_threshold_df['1 Person'] = poverty_threshold_df['1 Person'].str.replace('$', '').str.replace(',', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Employment & State Poverty Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639115, 15)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_merged = state_df.merge(poverty_state, on=['STATE', 'YEAR'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Writing all dataframes to CSV's**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_state.to_csv('../output/state_poverty.csv', index = False)\n",
    "poverty_nat.to_csv('../output/national_poverty.csv', index = False)\n",
    "nat_final_df.to_csv('../output/national_salary.csv', index = False)\n",
    "state_final_df.to_csv('../output/state_salary.csv', index = False)\n",
    "states_merged.to_csv('../output/state_poverty_and_income.csv', index = False)\n",
    "county_final.to_csv('../output/county_poverty.csv', index = False)\n",
    "poverty_threshold_df.to_csv('../output/poverty_threshold.csv', index = False)\n",
    "ue_final.to_csv('../output/unemployment.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
